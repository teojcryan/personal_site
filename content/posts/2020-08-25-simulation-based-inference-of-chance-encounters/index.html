---
title: Simulation-based Inference of Chance Encounters
author: Ryan Teo
date: '2020-08-25'
slug: simulation-based-inference-of-chance-encounters
categories:
  - R
tags:
  - simulation
description: "A simulation study on 1-1 interactions in social networking."
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>Recently, I had the opportunity to join a fellowship with 27 other fellows. As part of the fellowship, we would meet for regular discussions once a week with the guidance of 5 facilitators. The program has been immensely rewarding so far - but in this post I will discuss a probability problem that I’ve been pondering over since the first meeting.</p>
<p>The problem is as follows: Every week for 10 weeks, all 28 fellows (assuming no absentees, but this may be explored later) and 5 (barring absentees again) facilitators meet for a discussion. Each meeting will have at least one breakout session, where the 28 fellows will be separated into the same number of groups as there are facilitators - so usually, 5 - and have a discussion on the assigned readings. The allocation of fellows is independent between each breakout session. The organisers of the fellowship were concerned if there were enough opportunities for everyone to get to know each other during the breakout sessions.</p>
<p>We can address that question from two different angles. We can fix the number of breakout rounds in total and observe the distribution of the simulated interactions. With this we can ask how many times would the same two people interact with each other, and how many people would not have met. The alternative is to keep simulating until everyone has interacted with every other person at least once, and observe the number of rounds required.</p>
<p>I’m sure there are solutions based in permutations and combinatorics that can derive an exact solution to the questions above. My personal take is that not only are these solutions complicated and tedious, the results may also not be helpful. Having an understanding of the probabilistic distribution of the answers would be much more interesting and interpretable to account for random effects which happen all the time. To that end, I present my solution below with supplementary code in R.</p>
<div id="defining-the-breakout-function" class="section level3">
<h3>Defining the breakout function</h3>
<p>First, I defined a function that takes in the number of fellows <code>n_fellows</code> and number of facilitators <code>n_facils</code> and outputs a possible permutation of the fellows in the number of groups equal to <code>n_facils</code>. In other words, it randomly assigns a group (A,B,C,D,E,…) to each fellow. We will rely on this function to simulate the answer to our questions.</p>
<pre class="r"><code>breakout = function(n_fellows, n_facils = 5){
  # Takes in number of fellows and returns 
  # a possible permutation based on number of facilitators
  gpSize = n_fellows%/%n_facils
  remainder = n_fellows%%n_facils
  
  # Determine distribution of groups
  gpDist = rep(gpSize, n_facils)
  if (remainder&gt;0){gpDist[1:remainder] = gpDist[1:remainder] + 1}
  
  group = NULL
  for (i in 1:length(gpDist)){
    group = c(group, rep(LETTERS[i], gpDist[i]))
  }
  
  dist = cbind.data.frame(id = sample(1:n_fellows, size=n_fellows),
                          group)
  return(dist)
}</code></pre>
</div>
<div id="simulating-interactions-over-a-fixed-number-of-breakout-rounds" class="section level3">
<h3>Simulating interactions over a fixed number of breakout rounds</h3>
<p>The first angle focuses on the number of interactions between fellows after a fixed number of breakout rounds. To do this we first specify the essential parameters of the model. Here we assumed the <code>n_facils</code> to be fixed at 5.</p>
<pre class="r"><code>n_fellows = 28 # Number of fellows
N = 1000 # Number of simulations
rounds = 20 # Number of breakout rounds</code></pre>
<p>To track the total number of interactions between two particular fellows, we can store the results of each breakout round in a matrix <code>met</code>, which is initialised with the number of rows and columns equal to <code>n_fellows</code>. The simulation then proceeds as follows: at the start of every round of simulation, we set all interaction counts to 0 - that is, <code>met</code> is a 0 matrix. Then the breakout rounds will be simulated and the interaction between members of the same group in each round will increase by 1. At the end of the 20 breakout rounds, <code>met</code> will contain the number of interactions between each of the fellows.</p>
<pre class="r"><code>met_null = rep(NA, N)
met_mean = rep(NA, N)

for (n in 1:N){
  met = matrix(0L, nc=n_fellows, nr=n_fellows)
  for (round in 1:rounds){
    dist = breakout(n_fellows)
    
    # Check to see if fellows met, if met then 
    # their corresponding entry in met matrix increases by 1
    for (gp in dist$group %&gt;% unique){
      fellows = dist %&gt;% filter(group == gp) %&gt;% pull(id)
      for (i in fellows){
        for (j in fellows){
          met[i,j] = met[i,j] + 1
        }
      }
    }
  }
  met_mean[n] = ((rowSums(met) - (rounds))/n_fellows) %&gt;% mean
  met_null[n] = sum(met[upper.tri(met, diag=FALSE)] == 0)
}</code></pre>
<p>We can generate quite interesting inferences from the <code>met</code> matrices generated by the 1000 rounds of simulation. In the code above, <code>met_null</code> calculates at each round the number of interactions not made, i.e. when two particular fellows have not met. This is computed by taking the upper triangular matrix of <code>met</code> and counting the number of 0’s, that is, the number of no interactions. Also, <code>met_mean</code> tells us the average number of times any two fellows have had an interaction.</p>
<p><code>met_mean</code> is constant over each simulation and equal to 3.32. This means that on average, each fellow will meet every other fellow for 3.32 times. I don’t yet have an explanation for why it remains constant, but I think that the random effects over all the simulations are nullified by taking the mean of the number of interactions. I might be wrong.</p>
<center>
<img src="images/hist_null.png" style="width:80.0%" />
</center>
<p>The histogram of the number of no-interactions, or <code>met_null</code>, is plotted above. It seems that for 20 breakout rounds, on average there can be 10 missed interactions - meaning 10 pairs of interactions between fellows will not materialise. This is quite interesting to note - out of a possible 378 interactons (taking 27+26+25+…+1), only around 2.6% of interactions are missed. It might reflect a high level of success in helping fellows establish interactions with one another.</p>
</div>
<div id="simulating-the-number-of-breakout-rounds-needed-for-every-fellow-to-meet" class="section level3">
<h3>Simulating the number of breakout rounds needed for every fellow to meet</h3>
<p>Now instead of fixing the number of breakout rounds at 20, lets consider the number of breakout rounds it takes for every fellow to interact at least once. This would require every simulation to run a ‘while’ loop to keep simulating breakout rounds (in what might be the worst zoom-nightmare) until every fellow has met each other at least once. The code is attached below.</p>
<p>As with the previous simulation, the <code>met</code> matrix stores the interactions between each of the 28 fellows. However, the difference here is that it only has indicator (T/F) variables to store whether or not a pair of fellows have met, since we are not interested in the number of times they interacted. Similar to the previous simulation, when fellows are split into breakout groups, the matrix entry corresponding to their own and all their group mates will change to 1, indicating that they have interacted. The breakout groups will continue to be split over the ‘while’ loop, which runs until the total number of interactions exceeds <code>n_fellows^2</code>, which is sum of all entries in <code>met</code> when every fellow has met each other at least once.</p>
<pre class="r"><code>counts = rep(NA, N)
for (iter in 1:N){
  # initialise a nxn identity matrix to store &#39;met&#39;
  met = matrix(0L, nc=n_fellows, nr=n_fellows)
  
  # randomly allocate groups each time
  counter = 0
  # loop until everyone has met each other at least once
  while (sum(met) &lt; n_fellows^2){
    dist = breakout(n_fellows)
    
    # Check to see if fellows met, if met then 
    # their corresponding entry in met matrix = 1
    for (gp in dist$group %&gt;% unique){
      fellows = dist %&gt;% filter(group == gp) %&gt;% pull(id)
      for (i in fellows){
        for (j in fellows){
          met[i,j] = 1
        }
      }
    }
    counter = counter + 1
  }
  counts[iter] = counter
}</code></pre>
<p><code>counts</code> contains the number of breakout rounds required for every fellow to meet at least once in each simulation. The distribution of <code>counts</code> is plotted below.</p>
<center>
<img src="images/hist_rounds.png" style="width:80.0%" />
</center>
<p>We see that the number of breakout rounds needed for all fellows to meet has a wide range, from 22 to 71, with the mean concentrated around 35. This means that it would require an average of 3.5 breakout sessions every week for every fellow to meet each other at least once.</p>
<p>To understand both simulations, I conclude that although the results suggest that it takes on average 35 breakout sessions for all fellows to meet at least once, having 20 breakout sessions already has a high coverage of close to 97%. Pursuing an objective for every fellow to meet each other at least once might not be worth the cost of extending an additional 15 or so breakout sessions. As a caveat, the limitations of the simulations are clear - the number of interactions does not tell us anything about the quality of interactions that the fellows have, which is difficult to quantify in and of itself. At its core, the fellowship should prioritise the quality of interactions and discussions over the number of links created in the social network.</p>
<p>This was quite an entertaining and insightful exercise in simulation, and its comforting to know that I can solve some complex problems with simulation instead of probability theory.</p>
</div>
